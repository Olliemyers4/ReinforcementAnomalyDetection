{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import easydict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/JoungheeKim/autoencoder-lstm/blob/main/autoencoderLSTM_tutorial(english).ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,inputSize=3,hiddenSize=64,layers=2):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden = hiddenSize\n",
    "        self.layers = layers\n",
    "        self.lstm = nn.LSTM(inputSize, hiddenSize, layers, batch_first=True, dropout=0.1, bidirectional=False)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output, (hidden, cell) = self.lstm(x)\n",
    "        return (hidden, cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,inputSize=3,hiddenSize=64,layers=2,outputSize=3):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden = hiddenSize\n",
    "        self.layers = layers\n",
    "        self.lstm = nn.LSTM(inputSize, hiddenSize, layers, batch_first=True, dropout=0.1, bidirectional=False)\n",
    "        self.fc = nn.Linear(hiddenSize, outputSize)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        output, (hidden, cell) = self.lstm(x, hidden)\n",
    "        prediction = self.fc(output)\n",
    "        return prediction, (hidden, cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self,args):\n",
    "        super(Autoencoder,self).__init__()\n",
    "        self.encoder = Encoder(args.inputSize, args.hiddenSize, args.layers)\n",
    "        self.decoder = Decoder(args.inputSize, args.hiddenSize, args.layers, args.inputSize) # inputSize = outputSize - as you want to reconstruct the input\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.layers = args.layers\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        batch_size = x.size(0)\n",
    "        if hidden is None:\n",
    "            _, (hidden, cell) = self.encoder(x)\n",
    "            hidden = hidden.repeat(self.layers, 1, 1)\n",
    "            cell = cell.repeat(self.layers, 1, 1)\n",
    "        else:\n",
    "            hidden, cell = hidden\n",
    "\n",
    "        decode, _ = self.decoder(x, (hidden, cell))\n",
    "        return decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Autoencoder(inputSize=3, hiddenSize=64, layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args,model,train,test):\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=args.learningRate)\n",
    "\n",
    "    epochs = range(args.maxIter//len(train)+1) #fix var name of max_iter\n",
    "\n",
    "    count = 0\n",
    "    for epoch in epochs:\n",
    "        model.train()\n",
    "        optim.zero_grad()\n",
    "        for i, data in enumerate(train):\n",
    "            if count > args.maxIter:\n",
    "                return model\n",
    "            count += 1\n",
    "\n",
    "            input_data = data.unsqueeze(1).to(args.device)\n",
    "            #print(\"Shape of input_data:\", input_data.shape)  # Add this line to print the shape of input_data\n",
    "\n",
    "            # Initialize hidden and cell states\n",
    "            batch_size = input_data.size(0)\n",
    "            hidden = torch.zeros((args.layers * 1, batch_size, args.hiddenSize)).to(args.device)\n",
    "            cell = torch.zeros((args.layers * 1, batch_size, args.hiddenSize)).to(args.device)\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(input_data, (hidden, cell))\n",
    "            loss = model.criterion(output, input_data)\n",
    "\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "        model.eval()\n",
    "        evalLoss = 0\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(test):\n",
    "                input_data = data.unsqueeze(1).to(args.device)\n",
    "                # Initialize hidden and cell states\n",
    "                batch_size = input_data.size(0)\n",
    "                hidden = torch.zeros((args.layers * 1, batch_size, args.hiddenSize)).to(args.device)\n",
    "                cell = torch.zeros((args.layers * 1, batch_size, args.hiddenSize)).to(args.device)\n",
    "\n",
    "                # Forward pass\n",
    "                output = model(input_data, (hidden, cell))\n",
    "                loss = model.criterion(output, input_data)\n",
    "                evalLoss += loss.item()\n",
    "        evalLoss /= len(test)\n",
    "        print(f\"Epoch {epoch} - Eval Loss: {evalLoss}\")\n",
    "    return model\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## option Setting\n",
    "args = easydict.EasyDict({\n",
    "    \"batch_size\": 64, ## batch size setting\n",
    "    \"device\": torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'), ## whether use GPU\n",
    "    \"inputSize\": 3, ## input dimension setting (image is 64x64 = 4096)\n",
    "    \"hiddenSize\": 64, ## Hidden dimension setting\n",
    "    \"outputSize\": 3, ## output dimension setting\n",
    "    \"layers\": 2,     ## number of LSTM layer\n",
    "    \"learningRate\" : 0.0005, ## learning rate setting\n",
    "    \"maxIter\" : 100, ## max iteration setting\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Step 1: Prepare the Dataset\n",
    "clear = pd.read_csv('testClear.csv')\n",
    "# Assuming your data is in a single column and each row represents a timestep\n",
    "timeseries_tensorC = torch.tensor(clear[['value-0','value-1','value-2']].values, dtype=torch.float32)\n",
    "\n",
    "anom = pd.read_csv('testAnom.csv')\n",
    "# Assuming your data is in a single column and each row represents a timestep\n",
    "timeseries_tensorA = torch.tensor(anom[['value-0','value-1','value-2']].values, dtype=torch.float32)\n",
    "\n",
    "\n",
    "\n",
    "# Step 2: Create a Custom Dataset Class\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# Step 3: Use DataLoader to Load the Data\n",
    "datasetC = TimeSeriesDataset(timeseries_tensorC)\n",
    "datasetA = TimeSeriesDataset(timeseries_tensorA)\n",
    "batch_size = 64  # Set your desired batch size\n",
    "shuffle = False  # Set to True to have the data reshuffled at every epoch\n",
    "\n",
    "dataLoaderC = DataLoader(datasetC, batch_size=batch_size, shuffle=shuffle)\n",
    "dataLoaderA = DataLoader(datasetA, batch_size=1, shuffle=shuffle)\n",
    "\n",
    "# Usage example:\n",
    "# Iterate through the data_loader to get batches of data\n",
    "#for batch in data_loader:\n",
    "#    # Process each batch as needed\n",
    "#    print(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (encoder): Encoder(\n",
       "    (lstm): LSTM(3, 64, num_layers=2, batch_first=True, dropout=0.1)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (lstm): LSTM(3, 64, num_layers=2, batch_first=True, dropout=0.1)\n",
       "    (fc): Linear(in_features=64, out_features=3, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (criterion): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Autoencoder(args)\n",
    "model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Eval Loss: 0.0019196676148567349\n",
      "Epoch 1 - Eval Loss: 0.0018189580005127937\n",
      "Epoch 2 - Eval Loss: 0.0017798810877138749\n",
      "Epoch 3 - Eval Loss: 0.0017344260340905748\n",
      "Epoch 4 - Eval Loss: 0.0016503385122632608\n",
      "Epoch 5 - Eval Loss: 0.0016008839666028507\n"
     ]
    }
   ],
   "source": [
    "model = train(args,model,dataLoaderC,dataLoaderC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ollie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1, 1, 3])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "# Now you can use the trained model to make predictions on dataLoaderA\n",
    "\n",
    "model.eval()\n",
    "with open('output.csv', 'w') as f:\n",
    "    f.write(\"timestamp,reconstructionError-0,reconstructionError-1,reconstructionError-2\\n\")\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dataLoaderA):\n",
    "            input_data = data.unsqueeze(1).to(args.device)\n",
    "            # Initialize hidden and cell states\n",
    "            batch_size = input_data.size(0)\n",
    "            hidden = torch.zeros((args.layers * 1, batch_size, args.hiddenSize)).to(args.device)\n",
    "            cell = torch.zeros((args.layers * 1, batch_size, args.hiddenSize)).to(args.device)\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(input_data, (hidden, cell))\n",
    "            outputIndex1 = output[:,:,0] # This would be looped over for each output but can be static for now\n",
    "            outputIndex2 = output[:,:,1]\n",
    "            outputIndex3 = output[:,:,2]\n",
    "            loss1 = model.criterion(outputIndex1, input_data)\n",
    "            loss2 = model.criterion(outputIndex2, input_data)\n",
    "            loss3 = model.criterion(outputIndex3, input_data)\n",
    "            f.write(f\"{i},{loss1.item()},{loss2.item()},{loss3.item()}\\n\")\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
